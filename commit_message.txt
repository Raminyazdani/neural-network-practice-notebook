Ramin Yazdani | Neural Network MNIST Classifier | main | feat(fix): Fix learning rate: 0.05 → 0.5 for proper convergence

Fixed learning rate bug discovered during initial testing. The previous value of
0.05 was too conservative, causing very slow convergence and poor accuracy.
Increasing to 0.5 achieves the expected 90% accuracy.

What was changed:
- Learning rate: 0.05 → 0.5 (10× increase)

Problem observed:
- With LR=0.05: Loss barely decreased, stuck around 1.5-2.0 after 100 epochs
- Test accuracy only ~50% (far below expected 90%)
- Training was underutilizing gradient information

After fix:
- Loss decreases rapidly to 0.3-0.4
- Test accuracy ~90% as expected for this architecture
- Proper convergence in 100 epochs

How discovered: Ran training and observed poor accuracy. Compared to literature
values for similar architectures (typical LR range: 0.1-1.0). Re-ran with LR=0.5
and achieved expected performance.
