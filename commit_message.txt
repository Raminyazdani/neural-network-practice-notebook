Ramin Yazdani | Neural Network MNIST Classifier | main | WIP(eval): Add model evaluation code

Added evaluation code to compute and display test accuracy after training.
This enables measuring model performance on unseen data.

What was added:
- Prediction computation on test set after training
- Accuracy calculation: mean(predictions == true_labels)
- Formatted accuracy percentage output

Bug introduced: Used wrong variable name `X_testing` instead of `X_test` in the
prediction line. This will cause a NameError when the evaluation cell is run
because the preprocessing step created `X_test`, not `X_testing`. This typo
will be caught immediately when running the notebook and fixed in the next commit.

This demonstrates a common mistake when switching between naming conventions
(test vs testing).
