Ramin Yazdani | Neural Network MNIST Classifier | main | WIP(preprocessing): Implement one-hot encoding for labels

Extended the notebook with one-hot encoding functionality to prepare labels for
multi-class classification. The neural network output layer with softmax activation
requires one-hot encoded labels for proper cross-entropy loss computation.

What was added:
- One-hot encoding implementation using sklearn's OneHotEncoder
- Converts integer labels (0-9) to binary vectors (10 classes)
- Configuration: sparse_output=False for dense numpy arrays
- Updated README with preprocessing information

Rationale: This is a discrete preprocessing step that prepares labels in the format
needed by the softmax + cross-entropy loss function. Separated from other preprocessing
to keep commits focused and logical.
